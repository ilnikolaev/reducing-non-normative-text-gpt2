{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1c0b191-a2fe-454c-b4d4-d3c0352954ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 21:11:05.128506: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-07 21:11:05.157201: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-07 21:11:05.590063: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras_nlp\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985aebea-bd34-4a3f-84e5-572d106532ed",
   "metadata": {},
   "source": [
    "Define classifier & model hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9db2f3e3-2551-4ec6-8336-ebf42c6f1e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_preset = \"gpt2_base_en\"\n",
    "dataset = \"datasets/original.csv\"\n",
    "model_penalty = 0.8\n",
    "clf_vocab_size = 32000\n",
    "clf_maxlen = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cde467-12a7-4e0f-9855-6f2d11dfebab",
   "metadata": {},
   "source": [
    "Load GPT2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eedf159c-7be8-40b6-92e8-844462ee1008",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 21:11:06.567682: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-07 21:11:06.582019: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-07 21:11:06.582139: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-07 21:11:06.582783: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-07 21:11:06.582866: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-07 21:11:06.582916: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-07 21:11:06.632860: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-07 21:11:06.632980: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-07 21:11:06.633038: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-07 21:11:06.633087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10392 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.linalg.matmul), but are not present in its tracked objects:   <tf.Variable 'token_embedding/embeddings:0' shape=(50257, 768) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    }
   ],
   "source": [
    "gpt2_lm = keras_nlp.models.GPT2CausalLM.from_preset(model_preset)\n",
    "tokenizer = keras_nlp.models.GPT2Tokenizer.from_preset(model_preset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bbd9a5-9be4-44bb-b0aa-b29bee72c63d",
   "metadata": {},
   "source": [
    "Read the dataset and extract text data from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bb944e3-801c-4c96-a60b-016ad07d99aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(dataset)\n",
    "inputs = data.comment_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b990b456-830e-4b72-9b34-7ab3463c2b7f",
   "metadata": {},
   "source": [
    "This dataset contains float toxicity scores, but only 0 and 1 are needed to train the classifier, and its necessary to split toxicity values into two columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a8dff49-5b94-49c5-9555-a1435d01824d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    (data['severe_toxicity'] == 0), \n",
    "    (data['severe_toxicity'] > 0.0001),\n",
    "    ]\n",
    "\n",
    "val = [1, 0]\n",
    "\n",
    "data['not_toxic'] = np.select(conditions, val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba010f6-f1be-4a27-b326-5510aea863d7",
   "metadata": {},
   "source": [
    "Join toxicity columns in one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b23f1211-17ef-4cf6-8fcc-df9aea42f9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = data.pop(\"severe_toxicity\")\n",
    "nt = data.pop(\"not_toxic\")\n",
    "targets = pd.DataFrame(t).join(pd.DataFrame(nt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3133641-7026-4aa4-91d1-ce3ce40fd773",
   "metadata": {},
   "source": [
    "Replace the remaining values with 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8859e861-e48b-4660-895b-cb0a610b8178",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_38995/1622696461.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  targets[\"severe_toxicity\"].loc[targets[\"severe_toxicity\"] > 0.0001] = 1\n"
     ]
    }
   ],
   "source": [
    "targets[\"severe_toxicity\"].loc[targets[\"severe_toxicity\"] > 0.0001] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a00dca3c-03fe-4f20-9785-c8bdaca1b773",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = targets.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4079aef0-2f42-4223-949f-38a3b3b2b98d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>not_toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   severe_toxicity  not_toxic\n",
       "0                0          1\n",
       "1                0          1\n",
       "2                0          1\n",
       "3                0          1\n",
       "4                1          0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e30f02-e1b3-4f2c-b170-56ac72719240",
   "metadata": {},
   "source": [
    "Define classifier model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46c0138a-d267-4268-a39d-11b5b5971e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer = tf.keras.layers.TextVectorization(\n",
    " max_tokens=clf_vocab_size,\n",
    " output_mode='int',\n",
    " output_sequence_length=clf_maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d9f41f8-54bd-4f85-96a7-7c3d94d82701",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer.adapt(inputs[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51da23c9-d539-4f10-9d00-bd8acc08a7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(1,), dtype=tf.string),\n",
    "    vectorize_layer,\n",
    "    tf.keras.layers.Embedding(input_dim=clf_vocab_size+1, output_dim=256),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Conv1D(256, 5, activation='relu'),\n",
    "    tf.keras.layers.GlobalMaxPooling1D(),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(2, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65a8eb7e-498b-45b5-ab9f-79381f60f3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization (TextVec  (None, 200)              0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 200, 256)          8192256   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200, 256)          0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 196, 256)          327936    \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 256)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,520,706\n",
      "Trainable params: 8,520,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e479820a-e005-4563-b645-86a40bd9622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss=tf.keras.losses.BinaryCrossentropy(from_logits=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c70e033-bd30-484d-8afe-e183cb7d0378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 21:11:16.694458: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-08-07 21:11:16.823606: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-08-07 21:11:16.826149: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f009a0d6cf0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-08-07 21:11:16.826162: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2023-08-07 21:11:16.828646: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-08-07 21:11:16.902309: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 34s 53ms/step - loss: 0.2163\n",
      "Epoch 2/12\n",
      "625/625 [==============================] - 10s 16ms/step - loss: 0.1834\n",
      "Epoch 3/12\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.1779\n",
      "Epoch 4/12\n",
      "625/625 [==============================] - 5s 9ms/step - loss: 0.1584\n",
      "Epoch 5/12\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 0.1333\n",
      "Epoch 6/12\n",
      "625/625 [==============================] - 4s 6ms/step - loss: 0.1113\n",
      "Epoch 7/12\n",
      "625/625 [==============================] - 5s 7ms/step - loss: 0.0921\n",
      "Epoch 8/12\n",
      "625/625 [==============================] - 4s 6ms/step - loss: 0.0750\n",
      "Epoch 9/12\n",
      "625/625 [==============================] - 4s 6ms/step - loss: 0.0614\n",
      "Epoch 10/12\n",
      "625/625 [==============================] - 4s 6ms/step - loss: 0.0491\n",
      "Epoch 11/12\n",
      "625/625 [==============================] - 4s 6ms/step - loss: 0.0395\n",
      "Epoch 12/12\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.0323\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f04801d5070>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(inputs[:20000], targets[:20000], epochs=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d8a2f8-2d92-4e77-9237-636e872ec05e",
   "metadata": {},
   "source": [
    "Test classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "feb915f6-9f69-4245-a9c6-6314cd8dc071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 85ms/step\n",
      "normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 21:12:41.503368: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "p = classifier.predict(tf.Variable([\"Hello, world!\"]))\n",
    "if p[0][0] > p[0][1]:\n",
    "    print(\"toxic\")\n",
    "else:\n",
    "    print(\"normal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161c3fec-d37d-4395-a5dd-7160d3947ed6",
   "metadata": {},
   "source": [
    "Define word-wise crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "624bc9c2-2ff5-4aa1-ab2f-339e15fdccb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def word_loss(x,y,p=None):\n",
    "    x = x[0][y]\n",
    "    if p is not None:\n",
    "        return -tf.math.log(tf.nn.softmax(x)[y]) + p #Add punishment value, if its given\n",
    "    return -tf.math.log(tf.nn.softmax(x)[y])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5257a10-89aa-4ee8-b8a3-1bf716595650",
   "metadata": {},
   "source": [
    "Execute classifier on a given sentence to get its toxicity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12de04e2-0dac-4c2b-b54c-c4ea4986b438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(sentence):\n",
    "    result = classifier(tf.Variable([sentence]))\n",
    "    if result[0][0] > result[0][1]:\n",
    "        return 0 #0 = toxic\n",
    "    return 1 #1 = normative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe08ef8-878b-4203-9945-3d2244d15ace",
   "metadata": {},
   "source": [
    "Compute model sentence loss considering score of classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9661936-a80a-44b1-9c9c-08a416735d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def sentence_loss(score, x, y, penalty, i):\n",
    "    score = tf.cast(score, tf.float32)\n",
    "    mask = tf.range(start=0, limit=y.shape[1], delta=1)\n",
    "    \n",
    "    pd = 1 - i * 0.05 #Value to control penalty\n",
    "    \n",
    "    v = tf.map_fn(lambda j: word_loss(x, j), mask, dtype=tf.float32)\n",
    "    out = 1 / y.shape[1] * tf.reduce_sum(v)\n",
    "    \n",
    "    #Punishment function\n",
    "    pe = tf.cast(penalty, tf.float32) * tf.cast(pd, tf.float32) * (1.0 - score) * tf.cast(out, tf.float32)\n",
    "    \n",
    "    #Sentence loss\n",
    "    l = tf.map_fn(lambda j: word_loss(x, j, pe), mask, dtype=tf.float32)\n",
    "    out2 = 1 / y.shape[1] * tf.reduce_sum(l)\n",
    "    \n",
    "    return out2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99aa0973-5301-4f88-8b6f-8fcbb0c90254",
   "metadata": {},
   "source": [
    "Define optimizer and training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b74a145-0731-4fd0-89a8-98e1bda6d802",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.AdamW(learning_rate=4e-5, epsilon=1e-7, weight_decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39683c77-cee5-4d4e-99ab-a116eed9e8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(sentence, step_n):\n",
    "    sl = len(sentence)\n",
    "    s2 = gpt2_lm.generate(sentence, max_length=60) #Generate continuation sentence\n",
    "    \n",
    "    if len(sentence) >= len(s2):\n",
    "        result = sentence\n",
    "    else:\n",
    "        result = s2[sl+1:]\n",
    "    \n",
    "    score = get_score(result) #Get classifier score\n",
    "    \n",
    "    if result:\n",
    "        with tf.GradientTape() as tape:\n",
    "            result = tf.expand_dims(tokenizer.tokenize(result),0)\n",
    "\n",
    "            mask = np.not_equal(result, 0) #Create padding mask\n",
    "            logits = gpt2_lm([result, mask])\n",
    "\n",
    "            loss = sentence_loss(score, logits, result, model_penalty, step_n)\n",
    "\n",
    "        grads = tape.gradient(loss, gpt2_lm.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, gpt2_lm.trainable_variables))\n",
    "\n",
    "        return loss, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7464fed1-8ed0-4466-8d04-90c0855e9dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "c = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab9bb44-9cb8-4c97-8aef-0d1e938ee196",
   "metadata": {},
   "source": [
    "Run fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "986f19b4-109e-438d-99e4-7e61d061ba6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 21:12:44.639965: W tensorflow/compiler/tf2xla/kernels/categorical_op.cc:128] Warning: Using tf.random.categorical with XLA compilation will ignore seeds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ilya/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f03e9cee4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f03e9cee4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function sentence_loss at 0x7f03eafa9430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function sentence_loss at 0x7f03eafa9430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch: 10 step: 10 loss: 1.4877561 score: 1 \r"
     ]
    }
   ],
   "source": [
    "for i in range(1,epochs+1):\n",
    "    step = 1\n",
    "    for sentence in inputs[0:10]:\n",
    "        loss, score = train_step(sentence, c)\n",
    "        print(\"Epoch: \"+str(i)+\" step: \"+str(step)+\" loss: \"+str(loss.numpy()) + \" score: \"+str(score) + \" \", end='\\r')\n",
    "        c = c + 1\n",
    "        step = step + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
